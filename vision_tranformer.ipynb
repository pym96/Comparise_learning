{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPksE6Jg5aXkwQe1ZUiVqD1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pym96/Comparise_learning/blob/main/vision_tranformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image patching"
      ],
      "metadata": {
        "id": "yK3g2uO-yHgF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Hb6buvgDw1N7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision.datasets import OxfordIIITPet\n",
        "import matplotlib.pyplot as plt\n",
        "from random import random\n",
        "from torchvision.transforms import Resize, ToTensor\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "\n",
        "to_tensor = [Resize((144,144)), ToTensor()]\n",
        "\n",
        "class Compose(object):\n",
        "  def __init__(self, transforms):\n",
        "    self.transforms = transforms\n",
        "  def __call__(self, image, target):\n",
        "    for t in self.transforms:\n",
        "      image = t(image)\n",
        "    return image, target\n",
        "\n",
        "def show_images(images, num_samples=40, cols=8):\n",
        "  '''Plot some samples from dataset'''\n",
        "  plt.figure(figsize=(15,15))\n",
        "  idx = int(len(dataset) / num_samples)\n",
        "  print(images)\n",
        "  for i, img in enumerate(images):\n",
        "    if i % idx == 0:\n",
        "      plt.subplot(int(num_samples/cols) + 1, cols, int(i/idx) + 1)\n",
        "      plt.imshow(to_pil_image(img[0]))\n",
        "# 200 images for each pet\n",
        "dataset = OxfordIIITPet(root=\" \", download = True, transforms = Compose(to_tensor))\n",
        "show_images(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Patch  Image\n",
        "## The following is mainly from the above implementations"
      ],
      "metadata": {
        "id": "K8HvOEIw3v4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops\n",
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXd2gl634EHB",
        "outputId": "2992233c-75f6-4ffd-a5a0-2ac64e4415f6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from einops.layers.torch import Rearrange\n",
        "from torch import Tensor\n",
        "\n",
        "class PatchEmbedding(nn.Module):\n",
        "  def __init__(self, in_channels=3, patch_size=8, emb_size=128):\n",
        "    self.patch_size = patch_size\n",
        "    super().__init__()\n",
        "    self.projection = nn.Sequential(\n",
        "        # Break-down the image in s1 x s2 patches and flat them\n",
        "        Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_size, p2 = patch_size),\n",
        "        nn.Linear(patch_size * patch_size * in_channels, emb_size)\n",
        "    )\n",
        "  def forward(self, x: Tensor)-> Tensor:\n",
        "    x= self.projection(x)\n",
        "    return x\n",
        "# Run a quick test\n",
        "sample_datapoint = torch.unsqueeze(dataset[0][0], 0)\n",
        "print(\"Initial shape: \", sample_datapoint.shape)\n",
        "embedding = PatchEmbedding()(sample_datapoint)\n",
        "print(\"Patches shape: \", embedding.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "z3gZVlJdx1w7",
        "outputId": "f262b289-9411-4b32-9298-31217d89da64"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-b7027da4a48e>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Run a quick test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0msample_datapoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initial shape: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_datapoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPatchEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_datapoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model\n",
        "## Let's first implement all of the transformer building blocks. These blocks are inspired by the implemetations linked abov. I've left out some dropouts and normalizations at some places"
      ],
      "metadata": {
        "id": "b1jcBgbH8ofS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from einops import rearrange\n",
        "class Attention(nn.Module):\n",
        "  def __init__(self, dim, n_heads, dropout):\n",
        "    super().__init__()\n",
        "    self.n_heads = n_heads\n",
        "    self.att = torch.nn.MultiheadAttention(embed_dim=dim,\n",
        "                                           num_heads=n_heads,\n",
        "                                           dropout=dropout)\n",
        "    self.q = torch.nn.Linear(dim, dim)\n",
        "    self.k = torch.nn.Linear(dim, dim)\n",
        "    self.v = torch.nn.Linear(dim, dim)\n",
        "\n",
        "  def forward(self,x ):\n",
        "    q = self.q(x)\n",
        "    k = self.k(x)\n",
        "    v = self.v(x)\n",
        "    attn_output, attn_output_weights = self.att(x, x, x)\n",
        "    return attn_output"
      ],
      "metadata": {
        "id": "CDghoka08-qI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Attention(dim=128, n_heads=4, dropout=0.)(torch.ones((1, 5, 128))).shape"
      ],
      "metadata": {
        "id": "Wl9a1J3mx10m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PreNorm(nn.Module):\n",
        "  def __init__(self, dim, fn):\n",
        "    super().__init__()\n",
        "    self.norm = nn.LayerNorm(dim)\n",
        "    self.fn = fn\n",
        "  def forward(self, x, **kwargs):\n",
        "    return self.fn(self.norm(x), **kwargs)"
      ],
      "metadata": {
        "id": "WJWvH_Dox13M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "norm = PreNorm(128, Attention(dim=128, n_heads=4, dropout=0.))\n",
        "norm(torch.ones((1, 5, 128))).shape"
      ],
      "metadata": {
        "id": "SnlIpHeZ-m6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Sequential):\n",
        "  def __init__(self,dim, hidden_dim, dropout=0):\n",
        "    super().__init__(\n",
        "        nn.Linear(dim, hidden_dim),\n",
        "        nn.GELU(),\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(hidden_dim, dim),\n",
        "        nn.Dropout(dropout)\n",
        "    )\n",
        "ff = FeedForward(dim=128, hidden_dim=256)\n",
        "ff(torch.ones((1, 5, 128))).shape"
      ],
      "metadata": {
        "id": "A0V5oKoq-m9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualAdd(nn.Module):\n",
        "  def __init__(self, fn):\n",
        "    super().__init__()\n",
        "    self.fn = fn\n",
        "  def forward(self, x, **kwargs):\n",
        "    res = x\n",
        "    x = self.fn(x, **kwargs)\n",
        "    x += res\n",
        "    return x"
      ],
      "metadata": {
        "id": "h-5zS_5-_TIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "residual_att = ResidualAdd(Attention(dim=128, n_heads=4, dropout=0.))\n",
        "residual_att(torch.ones((1, 5, 128))).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "sIycAD0a_TJ4",
        "outputId": "a8af16de-206f-4af0-cb1b-bfa0227a7c37"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-e1882b1e6d42>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresidual_att\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResidualAdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_heads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresidual_att\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ResidualAdd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Not all parameters are like in the original implementation\n",
        "# Some Dropouts & Norms are missing"
      ],
      "metadata": {
        "id": "diBr6rr_BEsp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from einops import repeat\n",
        "\n",
        "class ViT(nn.Module):\n",
        "  def __init__(self, ch=3, img_size=144, patch_size=4, emb_dim=32,\n",
        "               n_layers = 6, out_dim=37, dropout=0.1, heads=2):\n",
        "    super(ViT, self).__init__()\n",
        "\n",
        "    # Attributes\n",
        "    self.channels = ch\n",
        "    self.height = img_size\n",
        "    self.width = img_size\n",
        "    self.patch_size = patch_size\n",
        "    self.n_layers = n_layers\n",
        "\n",
        "    # Patching\n",
        "    self.patch_embedding = PatchEmbedding(in_channels=ch,\n",
        "                                          patch_size=patch_size,\n",
        "                                          emb_size=emb_dim)\n",
        "\n",
        "    # Learnable params\n",
        "    num_patches = (img_size // patch_size) ** 2\n",
        "    self.pos_embedding = nn.Parameter(\n",
        "        torch.randn(1, num_patches + 1, emb_dim)\n",
        "    )\n",
        "    self.cls_token = nn.Parameter(torch.rand(1, 1, emb_dim))\n",
        "\n",
        "    # Transformer encoder\n",
        "    self.layers = nn.ModuleList([])\n",
        "    for _ in range(n_layers):\n",
        "      transformer_block = nn.Sequential(\n",
        "          ResidualAdd(PreNorm(emb_dim, Attention(emb_dim, n_heads = heads, dropout=dropout))),\n",
        "          ResidualAdd(PreNorm(emb_dim, FeedForward(emb_dim, emb_dim, dropout = dropout)))\n",
        "      )\n",
        "      self.layers.append(transformer_block)\n",
        "\n",
        "    # Classfication head\n",
        "    self.head = nn.Sequential(nn.LayerNorm(emb_dim), nn.Linear(emb_dim, out_dim))\n",
        "\n",
        "  def forward(self, img):\n",
        "    # Get patch embedding vectors\n",
        "    x = self.patch_embedding(img)\n",
        "    b, n, _ = x.shape\n",
        "\n",
        "    # Add cls token to inputs\n",
        "    cls_tokens = repeat(self.cls_token, '1 1 d -> b 1 d', b = b)\n",
        "    x = torch.cat([cls_tokens, x], dim=1)\n",
        "    x += self.pos_embedding[:, :(n + 1)]\n",
        "\n",
        "    # Transformer layers\n",
        "    for i in range(self.n_layers):\n",
        "      x = self.layers[i](x)\n",
        "\n",
        "    # Output based on classification token\n",
        "    return self.head(x[:, 0, :])\n",
        "\n",
        "model = ViT()\n",
        "print(model)\n",
        "model(torch.ones((1, 3, 144, 144)))"
      ],
      "metadata": {
        "id": "gpdENbdpASav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "N8I_U0h1JpH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "train_split = int(0.8 * len(dataset))\n",
        "train, test = random_split(dataset, [train_split, len(dataset) - train_split])\n",
        "\n",
        "train_dataloader = DataLoader(train, batch_size = 32, shuffle=True)\n",
        "test_dataloader = DataLoader(test, batch_size = 32, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "0pE3eiU4ASea",
        "outputId": "c1637e46-896c-49f8-8d9b-f01f670e5f04"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-0cce81f477c2>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtrain_split\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "device = 'cuda'\n",
        "model = ViT().to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(1000):\n",
        "  epoch_losses = []\n",
        "  model.train()\n",
        "  for step, (inputs, labels) in enumerate(train_dataloader):\n",
        "    inputs,labels =inputs.to(device), labels.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    epoch_losses.append(loss.item())\n",
        "  if epoch % 5 == 0:\n",
        "    print(f\">>> Epoch {epoch} train loss: \", np.mean(epoch_losses))\n",
        "    epoch_losses = []\n",
        "    # Something was strange when using this?\n",
        "    # model.eval()\n",
        "    for step, (inputs, labels) in enumerate(test_dataloader):\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      epoch_losses.append(loss.item())\n",
        "    print(f\">>> Epoch {epoch} test loss: \", np.mean(epoch_losses))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "C-QhWeT-KXlh",
        "outputId": "635b4c05-df84-4f70-db55-24d8be86e59d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-1d3e53912d83>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cuda'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mViT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ViT' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs, labels = next(iter(test_dataloader))\n",
        "inputs, labels = inputs.to(device), labels.to(device)\n",
        "outputs = model(inputs)\n",
        "\n",
        "print(\"Predicted classes\", outputs.argmax(-1))\n",
        "print(\"Actual classes\", labels)"
      ],
      "metadata": {
        "id": "biK7DhWYKUlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "lVsS0S3kJoh5"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ff4t31TLJojt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}